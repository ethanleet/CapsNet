{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "USE_GPU = True\n",
    "from model import *\n",
    "from data_loaders import load_mnist\n",
    "from tools import weights_init_xavier\n",
    "from stats import Statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as path\n",
    "SAVE_DIR = \"saved_models\"\n",
    "FILENAME = \"modelk.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(capsnet):\n",
    "  capsnet.conv_layer.conv.apply(weights_init_xavier)\n",
    "  capsnet.primary_capsules.apply(weights_init_xavier)\n",
    "  capsnet.decoder.apply(weights_init_xavier)\n",
    "  #nn.init.xavier_normal_(capsnet.digit_caps.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet = CapsNet(reconstruction_type=\"FC\") # FC or Conv\n",
    "if USE_GPU:\n",
    "  capsnet.cuda()\n",
    "optimizer = torch.optim.Adam(capsnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model not found; Model initialized.\n"
     ]
    }
   ],
   "source": [
    "filepath = path.join(SAVE_DIR, FILENAME)\n",
    "if path.isfile(filepath):\n",
    "  print(\"Saved model found\")\n",
    "  capsnet.load_state_dict(torch.load(filepath))\n",
    "else:\n",
    "  print(\"Saved model not found; Model initialized.\")\n",
    "  initialize_weights(capsnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hyperparameters\"\"\"\n",
    "max_epochs = 1000\n",
    "batch_size = 128\n",
    "train_loader, test_loader = load_mnist(batch_size)\n",
    "stats = Statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 \t Time: 141 \t Test: 0.015 \t Train: 0.002 \t Accuracy: 99.4600 Reconstruction: 0.0496\n",
      "Epoch:   1 \t Time: 105 \t Test: 0.015 \t Train: 0.002 \t Accuracy: 99.5600 Reconstruction: 0.0495\n",
      "Epoch:   2 \t Time: 104 \t Test: 0.015 \t Train: 0.002 \t Accuracy: 99.5000 Reconstruction: 0.0495\n",
      "Epoch:   3 \t Time: 105 \t Test: 0.015 \t Train: 0.001 \t Accuracy: 99.4800 Reconstruction: 0.0495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display_step = 450\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "  capsnet.train()\n",
    "  for batch, (data, target) in list(enumerate(train_loader)):\n",
    "    target = torch.eye(10).index_select(dim=0, index=target)\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    if USE_GPU:\n",
    "      data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, reconstructions, masked = capsnet(data, target)\n",
    "    data = data - data.min()\n",
    "    data = data / data.max() \n",
    "    loss, rec_loss = capsnet.loss(data, target, output, reconstructions)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    stats.track_train(loss.data.item(), rec_loss.data.item())\n",
    "    \n",
    "    if batch % display_step == 0 and batch != 0:\n",
    "      capsnet.eval()\n",
    "\n",
    "      for batch_id, (data, target) in enumerate(test_loader):\n",
    "        target = torch.eye(10).index_select(dim=0, index=target)\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if USE_GPU:\n",
    "          data,target = data.cuda(), target.cuda()\n",
    "\n",
    "        output, reconstructions, masked = capsnet(data)\n",
    "        loss, rec_loss = capsnet.loss(data, target, output, reconstructions)\n",
    "        \n",
    "        stats.track_test(loss.data.item(),rec_loss target, masked)\n",
    "        \n",
    "      stats.save_stats(epoch)\n",
    "\n",
    "      filepath = path.join(SAVE_DIR, \"model{}.pt\".format(epoch))\n",
    "      torch.save(capsnet.state_dict(), filepath)\n",
    "      capsnet.train()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "capsnet.eval()\n",
    "data, target = iter(test_loader).next()\n",
    "output, reconstruction, masked = capsnet(data.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.max((output**2).sum(dim=2).squeeze(), dim=1)[1].cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3) 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb44f0817b8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 30\n",
    "print(target[i], predictions[i])\n",
    "im = reconstruction[i,0].data.cpu().numpy()\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(im, cmap=\"gray\")\n",
    "im2 = data[i, 0].data.cpu().numpy()\n",
    "im2 += abs(im.min())\n",
    "im2 /= im.max()\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(im2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.RECONSTRUCTION_LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
